#ce fichier permet d'accéder aux images de MySQL et d'Airflow via Docker.
# Il est nécessaire de créer un fichier .env à la racine du projet pour définir les variables d'environnement.

services:
  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
    ports:
      - "3307:3306" # changed: map host port 3307 -> container port 3306
    volumes:
      - mysql-db-volume:/var/lib/mysql

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      - mysql
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+mysqlconnector://${MYSQL_USER}:${MYSQL_PASSWORD}@mysql:3306/${MYSQL_DATABASE}
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__DEFAULT_TIMEZONE: ${AIRFLOW_TIMEZONE}
      AIRFLOW_UID: "${AIRFLOW_UID}"
      AIRFLOW_GID: "${AIRFLOW_GID}"
      AIRFLOW__CORE__FERNET_KEY: "${FERNET_KEY}"
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: webserver
    restart: always

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      - mysql
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+mysqlconnector://${MYSQL_USER}:${MYSQL_PASSWORD}@mysql:3306/${MYSQL_DATABASE}
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__DEFAULT_TIMEZONE: ${AIRFLOW_TIMEZONE}
      AIRFLOW_UID: "${AIRFLOW_UID}"
      AIRFLOW_GID: "${AIRFLOW_GID}"
      AIRFLOW__CORE__FERNET_KEY: "${FERNET_KEY}"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: scheduler
    restart: always

volumes:
  mysql-db-volume:


#Etape 0 : créer un fichier .env à la racine du projet avec les variables d'environnement (et le fichier docker-compose.yml)

#Etape1 : lancer ensuite la commande suivante pour démarrer les services
# docker compose up --build -d

# docker compose up: permet de démarrer les services définis dans le fichier docker-compose.yml.
# par défaut recherche le fichier docker-compose.yml, pour changer faire ceci :
# docker compose -f mon_fichier.yml up -d
# --build : permet de reconstruire les images si nécessaire. (en cherchant les Dockerfile dans le dossier courant)
# -d :signifie détaché, ça lance les containers en arrière-plan.

# Etape 2 : créer la base de données Airflow et les tables nécessaires en exécutant la commande suivante :
# docker compose run --rm airflow-webserver airflow db migrate

# docker compose run: permet d'exécuter une commande dans un service défini dans le fichier docker-compose.yml.
# --rm: supprime le conteneur une fois la commande terminée.
# airflow-webserver: c'est le nom du service dans le fichier docker-compose.yml.
# airflow db migrate: c'est la commande Airflow pour créer la base de données et les tables nécessaires.

# Etape 3 : créer les connexions par défaut pour Airflow en exécutant la commande suivante :
# docker compose run --rm airflow-webserver airflow connections create-default-connections

# docker compose run: permet d'exécuter une commande dans un service défini dans le fichier docker-compose.yml.
# --rm: supprime le conteneur une fois la commande terminée.
# airflow-webserver: c'est le nom du service dans le fichier docker-compose.yml.
# airflow connections create-default-connections: c'est la commande Airflow pour créer les connexions par défaut.

# Etape 4 : on relance les services pour appliquer les changements et démarrer Airflow :
# docker compose down
# docker compose up --build -d

# CES COMMANDES NE SONT A FAIRE QU'UNE SEULE FOIS, POUR INITIALISER AIRFLOW.
# ENSUITE, POUR LANCER AIRFLOW, IL SUFFIT DE FAIRE :
# docker compose up --build -d

# RESUME:
# * création .env et docker-compose.yml
# * docker compose up -d
# * docker compose run --rm airflow-webserver airflow db migrate
# * docker compose run --rm airflow-webserver airflow connections create-default-connections
# * docker compose down
# * docker compose up -d

#Etape 5: création administrateur Airflow
# docker compose run --rm airflow-webserver airflow users create \
#     --username admin \
#     --firstname Firstname \
#     --lastname Lastname \
#     --role Admin \
#     --email example@email.com \
#     --password admin

#Etape fin : pour accéder à l'interface web d'Airflow, ouvrez votre navigateur et allez à l'adresse:
# http://localhost:8080

#BONUS:

# pour voir les containers en cours d'exécution, utilisez la commande :
# docker ps

# pour arrêter les services (et les supprimer), utilisez la commande :
# docker compose down

#pour voir les logs des services, utilisez la commande :
# docker compose logs -f (saisir le fichier que l'on veut voir, par exemple airflow-webserver)

#pour lancer du sql dans le container MySQL, utilisez la commande :
# docker exec -it airflow-experiments-mysql-1 bash
# docker exec: permet d'exécuter une commande dans un conteneur en cours d'exécution.
# -it: permet d'ouvrir un terminal interactif dans le conteneur.
# airflow-experiments-mysql-1: c'est le nom du conteneur MySQL, il peut varier selon votre configuration.
# bash: c'est le shell que vous voulez utiliser dans le conteneur.
# mysql -u airflow -p: cette commande vous connecte à MySQL en tant qu'utilisateur airflow. Vous devrez entrer le mot de passe défini dans votre fichier .env.
# bash: c'est le shell que vous voulez utiliser dans le conteneur.
# mysql -u airflow -p: cette commande vous connecte à MySQL en tant qu'utilisateur airflow. Vous devrez entrer le mot de passe défini dans votre fichier .env.
# bash: c'est le shell que vous voulez utiliser dans le conteneur.
# mysql -u airflow -p: cette commande vous connecte à MySQL en tant qu'utilisateur airflow. Vous devrez entrer le mot de passe défini dans votre fichier .env.
